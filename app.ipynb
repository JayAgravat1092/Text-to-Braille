{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d3c9cf4",
   "metadata": {},
   "source": [
    "### Gives the description of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d00fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings,logging\n",
    "def cap(image_url):\n",
    "    warnings.simplefilter('ignore')\n",
    "    logging.disable(logging.WARNING)\n",
    "    from transformers import pipeline\n",
    "    caption = pipeline('image-to-text')\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "    # URL of the image\n",
    "\n",
    "    # Display the image\n",
    "    display(Image(url=image_url))\n",
    "    text=caption(image_url)\n",
    "    return text[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c80944",
   "metadata": {},
   "source": [
    "### To convert Text into Braille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d155e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextToBraille(text):\n",
    "    braille_map = {\n",
    "        'a': '⠁',\n",
    "        'b': '⠃',\n",
    "        'c': '⠉',\n",
    "        'd': '⠙',\n",
    "        'e': '⠑',\n",
    "        'f': '⠋',\n",
    "        'g': '⠛',\n",
    "        'h': '⠓',\n",
    "        'i': '⠊',\n",
    "        'j': '⠚',\n",
    "        'k': '⠅',\n",
    "        'l': '⠇',\n",
    "        'm': '⠍',\n",
    "        'n': '⠝',\n",
    "        'o': '⠕',\n",
    "        'p': '⠏',\n",
    "        'q': '⠟',\n",
    "        'r': '⠗',\n",
    "        's': '⠎',\n",
    "        't': '⠞',\n",
    "        'u': '⠥',\n",
    "        'v': '⠧',\n",
    "        'w': '⠺',\n",
    "        'x': '⠭',\n",
    "        'y': '⠽',\n",
    "        'z': '⠵',\n",
    "        '1': '⠼⠁',\n",
    "        '2': '⠼⠃',\n",
    "        '3': '⠼⠉',\n",
    "        '4': '⠼⠙',\n",
    "        '5': '⠼⠑',\n",
    "        '6': '⠼⠋',\n",
    "        '7': '⠼⠛',\n",
    "        '8': '⠼⠓',\n",
    "        '9': '⠼⠊',\n",
    "        '0': '⠼⠚',\n",
    "        '!': '⠖',\n",
    "        '(': '⠶',\n",
    "        ')': '⠶',\n",
    "        '-': '⠤',\n",
    "        '{': '⠸⠜',\n",
    "        '[': '⠶⠠',\n",
    "        ']': '⠶⠠',\n",
    "        '}': '⠸⠜',\n",
    "        ':': '⠒',\n",
    "        ';': '⠆',\n",
    "        ',': '⠂',\n",
    "        '.': '⠲',\n",
    "        '/': '⠌',\n",
    "        '?': '⠦',\n",
    "        ' ': ' ',\n",
    "        '\\n': '\\n'\n",
    "    }\n",
    "    final_string = \"\"\n",
    "    for char in text:\n",
    "        char = char.lower()\n",
    "        if char in braille_map:\n",
    "            final_string += braille_map[char]\n",
    "        else:\n",
    "            continue\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b621cd",
   "metadata": {},
   "source": [
    "### Using Keras model to do OCR on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ee9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt\n",
    "def anotate(image_path):\n",
    "    # Create a pipeline\n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    \n",
    "\n",
    "    # Get an image\n",
    "#     image_path = 'C://Users//jayag//Desktop//Marwadi//SEM-6//Mini-Project//3.jpeg'\n",
    "    image = keras_ocr.tools.read(image_path)\n",
    "    \n",
    "\n",
    "    # Use the pipeline to extract text from the image\n",
    "    prediction_groups = pipeline.recognize([image])\n",
    "\n",
    "    # Plot the predictions\n",
    "    fig, ax = plt.subplots()\n",
    "    keras_ocr.tools.drawAnnotations(image=image, predictions=prediction_groups[0], ax=ax)\n",
    "    plt.savefig(\"static/result.jpg\")\n",
    "    \n",
    "        # Extract Predictions\n",
    "    prediction_groups = pipeline.recognize([image])\n",
    "\n",
    "    # Group words by their y-coordinate to identify lines of text\n",
    "    line_groups = {}\n",
    "    for word_group in prediction_groups[0]:\n",
    "        y_coordinate = round(word_group[1][0][1], 2)  # Round y-coordinate to handle floating point errors\n",
    "        if y_coordinate in line_groups:\n",
    "            line_groups[y_coordinate].append(word_group)\n",
    "        else:\n",
    "            line_groups[y_coordinate] = [word_group]\n",
    "\n",
    "    # Sort the lines based on their y-coordinate\n",
    "    sorted_lines = sorted(line_groups.items(), key=lambda item: item[0])\n",
    "\n",
    "    # Extract words from sorted lines and combine them to form the final sequence\n",
    "    detected_sequence = ''\n",
    "    for _, line in sorted_lines:\n",
    "        # Sort words within each line based on their x-coordinate\n",
    "        sorted_words = sorted(line, key=lambda word_group: word_group[1][0][0])\n",
    "        line_words = [word_group[0] for word_group in sorted_words]\n",
    "\n",
    "        # Check text direction\n",
    "        if len(line_words) >= 2 and sorted_words[0][1][0][0] > sorted_words[1][1][0][0]:\n",
    "            # If the text is detected from right to left, reverse the order of words within the line\n",
    "            line_words.reverse()\n",
    "\n",
    "        line_text = ' '.join(line_words)\n",
    "        detected_sequence += line_text + ' '\n",
    "\n",
    "    # Print the final sequence\n",
    "    print(\"Detected Sequence:\", detected_sequence)\n",
    "    return detected_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096854d6",
   "metadata": {},
   "source": [
    "### Main flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Jul/2024 17:11:29] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jul/2024 17:11:29] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [06/Jul/2024 17:11:33] \"GET /image_to_text HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\jayag\\.keras-ocr\\craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From C:\\Users\\jayag\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Jul/2024 17:11:43] \"POST /image_to_text HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from gtts import gTTS\n",
    "# from ultralytics import YOLO\n",
    "import cv2\n",
    "# import cvzone\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/image_to_text', methods=['GET', 'POST'])\n",
    "def image_to_text():\n",
    "    if request.method == 'POST':\n",
    "        if 'image' not in request.files:\n",
    "            return \"No image found in request!\"\n",
    "        image = request.files['image']\n",
    "        if image.filename == '':\n",
    "            return \"No image selected!\"\n",
    "        try:\n",
    "            result = anotate(image)\n",
    "            result=TextToBraille(result)\n",
    "            return render_template('image_to_text.html', result=result,path=image)\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "    else:\n",
    "        return render_template('image_to_text.html')\n",
    "    \n",
    "    \n",
    "@app.route('/image_to_speech', methods=['GET', 'POST'])\n",
    "def image_to_speech():\n",
    "    result=0\n",
    "    if request.method == 'POST':\n",
    "        if 'image' not in request.files:\n",
    "            return \"No image found in request!\"\n",
    "\n",
    "        image = request.files['image']\n",
    "        if image.filename == '':\n",
    "            return \"No image selected!\"\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image)\n",
    "            text = pytesseract.image_to_string(img)\n",
    "#             text = anotate(image)\n",
    "            \n",
    "\n",
    "            # Convert text to speech\n",
    "            tts = gTTS(text=text, lang='en')\n",
    "            tts.save(\"static/output.mp3\")\n",
    "            result=1\n",
    "            # Return the path to the generated speech file\n",
    "            return render_template('image_to_speech.html',result=result,text=text)\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "    else:\n",
    "        return render_template('image_to_speech.html')\n",
    "    \n",
    "@app.route('/object_detection', methods=['GET', 'POST'])\n",
    "def object_detection():\n",
    "    if request.method == 'POST':\n",
    "        url = request.form['url']\n",
    "        try:\n",
    "            result = cap(url)\n",
    "            return render_template('object_detection.html', result=result)\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "    else:\n",
    "        return render_template('object_detection.html')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True,use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5af35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2399d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
